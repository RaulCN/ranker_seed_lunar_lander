# ranker_seed_lunar_lander

Este projeto implementa um m√©todo de **Curriculum Learning** adaptativo para treinar um agente de Deep Reinforcement Learning (DRL) no ambiente `LunarLander-v3` do **Gymnasium**. O agente √© treinado usando o algoritmo **PPO** (*Proximal Policy Optimization*) da biblioteca **Stable Baselines3**.

A abordagem principal √© **ranquear as sementes (seeds)** do ambiente para identificar os cen√°rios de pouso mais f√°ceis e mais dif√≠ceis. O agente come√ßa a treinar nos cen√°rios mais f√°ceis e, √† medida que sua performance melhora, ele √© gradualmente exposto a ambientes mais complexos, acelerando e estabilizando o aprendizado.

---

## üìå Funcionalidades

- **Ranking de Sementes**  
  Script separado (`ranking_seeds.py`) avalia 100 sementes do ambiente `LunarLander-v3` para criar um ranking de dificuldade.  
  Isso gera o arquivo `lunar_seeds_ranking.csv`, base para o curriculum.

- **Curriculum Learning Adaptativo**  
  O treinamento √© dividido em fases. O agente come√ßa em um ambiente simplificado e progride para cen√°rios com mais vento e turbul√™ncia.

- **Otimiza√ß√£o de Hiperpar√¢metros Seguros**  
  Agendadores de aprendizado (`learning_rate` e `clip_range`) ajustam-se dinamicamente ao longo do treinamento, mantendo o processo mais est√°vel.

- **Mecanismo de Regress√£o Controlada**  
  Se a performance cair drasticamente em uma fase mais dif√≠cil, o ambiente √© temporariamente facilitado para permitir recupera√ß√£o, evitando "desaprendizado".

- **Customiza√ß√£o do Ambiente com Wrappers**  
  Utiliza *wrappers* como `LunarLanderAdaptiveWrapper`, `HarderLanderWrapper`, `EasierLanderWrapper` e `StepPenaltyWrapper` para modificar dinamicamente dificuldade e recompensa em tempo real.

---

## ‚öôÔ∏è Pr√©-requisitos

- Python 3.8+
- `gymnasium`
- `stable_baselines3`
- `pandas`
- `numpy`
- `tqdm` *(opcional, para barra de progresso no script de ranking)*

Instale as depend√™ncias com:

```bash
pip install gymnasium stable-baselines3 pandas numpy tqdm
